{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conv2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisha1729/lottery-ticket/blob/master/Conv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk7TBCHzKmHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install inferno-pytorch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZaP4uS3aBqs0",
        "outputId": "607c3478-30ca-4984-d8d3-939dba42aa50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from inferno.extensions.layers.reshape import Flatten\n",
        "from builtins import range\n",
        "from math import sqrt, ceil\n",
        "  \n",
        "  \n",
        "def weights_init(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        m.weight.data.normal_(0.0, 1e-3)\n",
        "        m.bias.data.fill_(0.)\n",
        "\n",
        "def update_lr(optimizer, lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "#--------------------------------\n",
        "# Device configuration\n",
        "#--------------------------------\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device: %s'%device)\n",
        "\n",
        "#--------------------------------\n",
        "# Hyper-parameters\n",
        "#--------------------------------\n",
        "input_size = 3\n",
        "num_classes = 10\n",
        "hidden_size = [64,128,256,512]\n",
        "fc_size = 256\n",
        "num_epochs = 10\n",
        "batch_size = 200\n",
        "learning_rate = 2e-3\n",
        "learning_rate_decay = 0.95\n",
        "reg=0.001\n",
        "num_training= 49000\n",
        "num_validation =1000\n",
        "norm_layer = None\n",
        "prune_percent = 30\n",
        "\n",
        "#  Initialising the initial mask with all ones\n",
        "mask_layerwise = {};\n",
        "\n",
        "\n",
        "#-------------------------------------------------\n",
        "# Load the CIFAR-10 dataset\n",
        "#-------------------------------------------------\n",
        "data_aug_transforms = []\n",
        "\n",
        "norm_transform = transforms.Compose(data_aug_transforms+[transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                     ])\n",
        "test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                     ])\n",
        "cifar_dataset = torchvision.datasets.CIFAR10(root='datasets/',\n",
        "                                           train=True,\n",
        "                                           transform=norm_transform,\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='datasets/',\n",
        "                                          train=False,\n",
        "                                          transform=test_transform\n",
        "                                          )\n",
        "#-------------------------------------------------\n",
        "# Prepare the training and validation splits\n",
        "#-------------------------------------------------\n",
        "mask = list(range(num_training))\n",
        "train_dataset = torch.utils.data.Subset(cifar_dataset, mask)\n",
        "mask = list(range(num_training, num_training + num_validation))\n",
        "val_dataset = torch.utils.data.Subset(cifar_dataset, mask)\n",
        "\n",
        "#-------------------------------------------------\n",
        "# Data loader\n",
        "#-------------------------------------------------\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=False)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "\n",
        "#-------------------------------------------------\n",
        "# Convolutional neural network\n",
        "#-------------------------------------------------\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layers, num_classes, norm_layer=None):\n",
        "        super(ConvNet, self).__init__()\n",
        "        #######################################################################################################\n",
        "        # The Conv-2, Conv-4, and Conv-6 architectures are variants of the VGG (Simonyan & Zisserman,\n",
        "        # 2014) network architecture scaled down for the CIFAR10 (Krizhevsky & Hinton, 2009) dataset. Like\n",
        "        # VGG, the networks consist of a series of modules. Each module has two layers of 3x3 convolutional\n",
        "        # filters followed by a maxpool layer with stride 2. After all of the modules are two fully-connected\n",
        "        # layers of size 256 followed by an output layer of size 10; in VGG, the fully-connected layers are of\n",
        "        # size 4096 and the output layer is of size 1000. Like VGG, the first module has 64 convolutions in\n",
        "        # each layer, the second has 128, the third has 256, etc. The Conv-2, Conv-4, and Conv-6 architectures\n",
        "        # have 1, 2, and 3 modules, respectively.\n",
        "        #######################################################################################################\n",
        "        layers = []\n",
        "        \n",
        "        # 1 module for Conv-2\n",
        "        layers.append(nn.Conv2d(input_size, 64 , kernel_size = 3, stride = 1, padding = 1))\n",
        "#         layers.append(nn.BatchNorm2d(64))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Conv2d(64, 64 , kernel_size = 3, stride = 1, padding = 1))\n",
        "#         layers.append(nn.BatchNorm2d(64))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0))\n",
        "        \n",
        "        # Fully Connected Layers\n",
        "        layers.append(Flatten())\n",
        "        \n",
        "        layers.append(nn.Linear(16384, fc_size))\n",
        "        layers.append(nn.Linear(fc_size, fc_size))\n",
        "        \n",
        "        # Output Layer\n",
        "        layers.append(nn.Linear(fc_size, num_classes))\n",
        "        \n",
        "        self.layers = nn.Sequential(*layers)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layers(x)\n",
        "        return out\n",
        "      \n",
        "def PrintModelSize(model, disp=True):\n",
        "    model_sz = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(\"Number of trainable parameters = \", model_sz)\n",
        "    return model_sz\n",
        "\n",
        "  \n",
        "def VisualizeFilter(model):\n",
        "    w = model.layers[0].weight\n",
        "    w_grid = torchvision.utils.make_grid(w,8, normalize = True, scale_each = True)\n",
        "    w_grid = w_grid.permute(2, 1, 0)\n",
        "    plt.imshow(w_grid.detach().cpu().numpy())    \n",
        "    return w_grid;\n",
        "  \n",
        "def prune(prune_percent, model, mask_layerwise):\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            sort_array = torch.sort(torch.abs(torch.masked_select(param, mask_layerwise[name]))).values\n",
        "            thres_index = int(percent*len(sort_array)/100)\n",
        "            threshold = sort_array[thres_index]\n",
        "            new_mask = torch.where(torch.abs(param).cpu() <= threshold.cpu(), torch.zeros(mask_layerwise[name].shape).byte().cpu(), mask_layerwise[name].cpu()).float().cuda()\n",
        "            new_param = param*new_mask\n",
        "            mask_layerwise[name] = new_mask        # Updating mask\n",
        "            param = new_param                      # Updating param\n",
        "            model.state_dict()[name].data.copy_(param)\n",
        "\n",
        "  \n",
        "model = ConvNet(input_size, hidden_size, num_classes, norm_layer=norm_layer).to(device)\n",
        "model.apply(weights_init)\n",
        "# Initialising mask with all ones\n",
        "for name, param in model.named_parameters():\n",
        "    mask_layerwise[name] = (torch.ones(param.size()).byte().to(device))\n",
        "\n",
        "# Print the model\n",
        "print(model)\n",
        "\n",
        "\n",
        "# Print model size\n",
        "PrintModelSize(model)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=reg)\n",
        "loss_history = []\n",
        "\n",
        "# Train the model\n",
        "lr = learning_rate\n",
        "max_val_acc = 0\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "      \n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        \n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_history.append(loss.item())\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "    \n",
        "    # TRAINING\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        train_accuracy.append(100*correct/total)\n",
        "    \n",
        "    # Code to update the lr\n",
        "    lr *= learning_rate_decay\n",
        "    update_lr(optimizer, lr)\n",
        "    model.eval()\n",
        "    \n",
        "    # VALIDATION\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        val_accuracy.append(100*correct/total)\n",
        "\n",
        "        print('Validataion accuracy is: {} %'.format(100 * correct / total))\n",
        "        \n",
        "        # Saving best model\n",
        "        if(correct/total>max_val_acc):\n",
        "          print(\"Saving the model...\")\n",
        "          torch.save(model.state_dict(), 'model_early.ckpt')\n",
        "          max_val_acc = correct/total\n",
        "\n",
        "    model.train()\n",
        "\n",
        "# plt.plot(loss_history)\n",
        "\n",
        "# TESTING\n",
        "\n",
        "# Test the model before pruning\n",
        "model.eval()\n",
        "\n",
        "# Load the best model\n",
        "best_model = torch.load(\"model_early.ckpt\")\n",
        "model.load_state_dict(best_model)\n",
        "\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        if total == 1000:\n",
        "            break\n",
        "\n",
        "    print('Accuracy of the network before pruning on the {} test images: {} %'.format(total, 100 * correct / total))\n",
        "\n",
        "for param in model.parameters():\n",
        "  print(param)\n",
        "  break\n",
        "  \n",
        "  \n",
        "# Pruning the network\n",
        "print(\"\\n\\n*********Pruning***********\\n\\n\")\n",
        "prune(prune_percent, model, mask_layerwise)\n",
        "\n",
        "\n",
        "for param in model.parameters():\n",
        "  print(param)\n",
        "  break\n",
        "  \n",
        "\n",
        "# Test the model after pruning\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        if total == 1000:\n",
        "            break\n",
        "\n",
        "    print('Accuracy of the network after pruning on the {} test images: {} %'.format(total, 100 * correct / total))\n",
        "\n",
        "# plt.plot(val_accuracy, label = \"Validation\")\n",
        "# plt.plot(train_accuracy, label = \"Train\")\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), 'model.ckpt')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Files already downloaded and verified\n",
            "ConvNet(\n",
            "  (layers): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Flatten()\n",
            "    (6): Linear(in_features=16384, out_features=256, bias=True)\n",
            "    (7): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (8): Linear(in_features=256, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Number of trainable parameters =  4301642\n",
            "Epoch [1/10], Step [100/245], Loss: 1.5699\n",
            "Epoch [1/10], Step [200/245], Loss: 1.2800\n",
            "Validataion accuracy is: 58.4 %\n",
            "Saving the model...\n",
            "Epoch [2/10], Step [100/245], Loss: 1.1284\n",
            "Epoch [2/10], Step [200/245], Loss: 1.2916\n",
            "Validataion accuracy is: 58.9 %\n",
            "Saving the model...\n",
            "Epoch [3/10], Step [100/245], Loss: 1.0318\n",
            "Epoch [3/10], Step [200/245], Loss: 0.8737\n",
            "Validataion accuracy is: 64.9 %\n",
            "Saving the model...\n",
            "Epoch [4/10], Step [100/245], Loss: 1.0103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfmI0dN4IO6P",
        "colab_type": "code",
        "outputId": "5473feba-880b-4ae0-f6c8-b6525d359609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(param.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 3, 3, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjjMkYqRRVij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# current_mask = torch.ones(param.size()).to(device)\n",
        "percent = 10\n",
        "# for param in model.named_parameters():\n",
        "print(\"Before pruning\")\n",
        "print(param)\n",
        "mask = torch.ones(param.size()).byte().to(device)\n",
        "print(type(param))\n",
        "print(type(mask))\n",
        "print(type(torch.zeros(mask.shape)))\n",
        "sort_array = torch.sort(torch.abs(torch.masked_select(param, mask))).values\n",
        "print(\"Sort aray = \", sort_array)\n",
        "thres_index = int(percent*len(sort_array)/100)\n",
        "print(\"Thres index = \", thres_index)\n",
        "threshold = sort_array[thres_index]\n",
        "# new_mask = param.le(threshold).float()\n",
        "mask = mask.cpu()\n",
        "print(torch.zeros(mask.shape).byte().cpu().is_cuda)\n",
        "print(mask.is_cuda)\n",
        "new_mask = torch.where(torch.abs(param).cpu() <= threshold.cpu(), torch.zeros(mask.shape).byte().cpu(), mask.cpu()).float().cuda()\n",
        "param_new = param*new_mask\n",
        "print(\"Threshold = \", threshold)\n",
        "print(new_mask)\n",
        "print(\"After pruning\")\n",
        "print(param_new)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m51lvYwYIiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(mask_layerwise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHZoXAYfY_A8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxMiezeCYIeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in model.named_parameters():\n",
        "#   print(name)\n",
        "  print(param)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGFpRnjJLCrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  Working Code\n",
        "\n",
        "#  Initialising the initial mask with all ones\n",
        "mask_layerwise = {};\n",
        "for name, param in model.named_parameters():\n",
        "    mask_layerwise[name] = (torch.ones(param.size()).byte().to(device))\n",
        "\n",
        "\n",
        "# Pruning the weights \n",
        "for name, param in model.named_parameters():\n",
        "  if 'weight' in name:\n",
        "    sort_array = torch.sort(torch.abs(torch.masked_select(param, mask_layerwise[name]))).values\n",
        "    thres_index = int(percent*len(sort_array)/100)\n",
        "    threshold = sort_array[thres_index]\n",
        "    new_mask = param.ge(threshold).float()\n",
        "    new_param = param*new_mask\n",
        "    mask_layerwise[name] = new_mask        # Updating mask\n",
        "    param = new_param                      # Updating param\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRGZqj5wHvxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in model.parameters():\n",
        "  current_mask = torch.ones(param.size()).to(device)\n",
        "  param, new_mask = prune(prune_percent, param, current_mask)\n",
        "\n",
        "# Test the model after pruning\n",
        "model.eval()\n",
        "\n",
        "# TODO: Early Stopping\n",
        "\n",
        "with torch.no_grad():\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        if total == 1000:\n",
        "            break\n",
        "\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(total, 100 * correct / total))\n",
        "\n",
        "plt.plot(val_accuracy, label = \"Validation\")\n",
        "plt.plot(train_accuracy, label = \"Train\")\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oo5Q6O_6Bhwy",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "x = torch.tensor([[1,2,3,4],[2,4,1,3],[5,8,2,4],[5,3,6,1],[6,4,2,6]]).float()\n",
        "percent = 20\n",
        "print(\"Original x\")\n",
        "print(x)\n",
        "print(torch.masked_select(x, mask))\n",
        "# current_mask = x.ge(-100)\n",
        "mask = torch.ones(x.size()).byte()\n",
        "x_sort_tensor = torch.sort(x)\n",
        "x_sort_array = torch.sort(torch.abs(torch.masked_select(x, mask))).values\n",
        "print(x_sort_array)\n",
        "thres_index = int(percent*len(x_sort_array)/100)\n",
        "threshold = x_sort_array[thres_index]\n",
        "print(thres_index)\n",
        "print(type(x))\n",
        "print(type(mask))\n",
        "print(type(torch.zeros(mask.shape)))\n",
        "new_mask = torch.where(torch.abs(x) <= threshold, torch.zeros(mask.shape).byte(), mask).float()\n",
        "# new_mask = x.ge(threshold).float()\n",
        "print(\"Threshold = \", threshold)\n",
        "print(\"New Mask\")\n",
        "print(new_mask)\n",
        "x_new = x*new_mask\n",
        "print(\"Pruned x\")\n",
        "print(x_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlNZZ1Ulr0uX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "summary(model, (3, 32, 32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPGj-1wNsSLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}