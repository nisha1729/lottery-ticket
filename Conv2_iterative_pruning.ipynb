{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conv2_iterative_pruning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nisha1729/lottery-ticket/blob/master/Conv2_iterative_pruning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGMFJhyn33wr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install inferno-pytorch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUMib2ep3v0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from inferno.extensions.layers.reshape import Flatten\n",
        "from builtins import range\n",
        "from math import sqrt, ceil\n",
        "\n",
        "global best_val_acc\n",
        "\n",
        "def weights_init(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        m.weight.data.normal_(0.0, 1e-3)\n",
        "        m.bias.data.fill_(0.)\n",
        "\n",
        "\n",
        "def update_lr(optimizer, lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "\n",
        "# --------------------------------\n",
        "# Device configuration\n",
        "# --------------------------------\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device: %s' % device)\n",
        "\n",
        "# --------------------------------\n",
        "# Hyper-parameters\n",
        "# --------------------------------\n",
        "input_size = 3\n",
        "num_classes = 10\n",
        "hidden_size = [64, 128, 256, 512]\n",
        "fc_size = 256\n",
        "num_epochs = 5\n",
        "batch_size = 200\n",
        "learning_rate = 2e-3  # 0.0002 in paper\n",
        "learning_rate_decay = 0.95\n",
        "reg = 0.001\n",
        "num_training = 49000\n",
        "num_validation = 1000\n",
        "norm_layer = None\n",
        "prune_percent = 20\n",
        "prune_iter = 20\n",
        "\n",
        "#  Initialising the initial mask with all ones\n",
        "mask_layerwise = {};\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Load the CIFAR-10 dataset\n",
        "# -------------------------------------------------\n",
        "data_aug_transforms = []\n",
        "\n",
        "norm_transform = transforms.Compose(data_aug_transforms + [transforms.ToTensor(),\n",
        "                                                           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                                           ])\n",
        "test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                     ])\n",
        "cifar_dataset = torchvision.datasets.CIFAR10(root='datasets/',\n",
        "                                             train=True,\n",
        "                                             transform=norm_transform,\n",
        "                                             download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='datasets/',\n",
        "                                            train=False,\n",
        "                                            transform=test_transform\n",
        "                                            )\n",
        "# -------------------------------------------------\n",
        "# Prepare the training and validation splits\n",
        "# -------------------------------------------------\n",
        "mask = list(range(num_training))\n",
        "train_dataset = torch.utils.data.Subset(cifar_dataset, mask)\n",
        "mask = list(range(num_training, num_training + num_validation))\n",
        "val_dataset = torch.utils.data.Subset(cifar_dataset, mask)\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Data loader\n",
        "# -------------------------------------------------\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=False)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Convolutional neural network\n",
        "# -------------------------------------------------\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layers, num_classes, norm_layer=None):\n",
        "        super(ConvNet, self).__init__()\n",
        "        #######################################################################################################\n",
        "        # The Conv-2, Conv-4, and Conv-6 architectures are variants of the VGG (Simonyan & Zisserman,\n",
        "        # 2014) network architecture scaled down for the CIFAR10 (Krizhevsky & Hinton, 2009) dataset. Like\n",
        "        # VGG, the networks consist of a series of modules. Each module has two layers of 3x3 convolutional\n",
        "        # filters followed by a maxpool layer with stride 2. After all of the modules are two fully-connected\n",
        "        # layers of size 256 followed by an output layer of size 10; in VGG, the fully-connected layers are of\n",
        "        # size 4096 and the output layer is of size 1000. Like VGG, the first module has 64 convolutions in\n",
        "        # each layer, the second has 128, the third has 256, etc. The Conv-2, Conv-4, and Conv-6 architectures\n",
        "        # have 1, 2, and 3 modules, respectively.\n",
        "        #######################################################################################################\n",
        "        layers = []\n",
        "\n",
        "        # 1 module for Conv-2\n",
        "        layers.append(nn.Conv2d(input_size, 64, kernel_size=3, stride=1, padding=1))\n",
        "        #         layers.append(nn.BatchNorm2d(64))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1))\n",
        "        #         layers.append(nn.BatchNorm2d(64))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.MaxPool2d(kernel_size=2, stride=2, padding=0))\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        layers.append(Flatten())\n",
        "        #         16384\n",
        "        layers.append(nn.Linear(16384, fc_size))\n",
        "        layers.append(nn.Linear(fc_size, fc_size))\n",
        "\n",
        "        # Output Layer\n",
        "        layers.append(nn.Linear(fc_size, num_classes))\n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layers(x)\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                new_param = param * mask_layerwise[name].float()\n",
        "                model.state_dict()[name].data.copy_(new_param)\n",
        "        return out\n",
        "\n",
        "\n",
        "def PrintModelSize(model, disp=True):\n",
        "    model_sz = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(\"Number of trainable parameters = \", model_sz)\n",
        "    return model_sz\n",
        "\n",
        "\n",
        "def VisualizeFilter(model):\n",
        "    w = model.layers[0].weight\n",
        "    w_grid = torchvision.utils.make_grid(w, 8, normalize=True, scale_each=True)\n",
        "    w_grid = w_grid.permute(2, 1, 0)\n",
        "    plt.imshow(w_grid.detach().cpu().numpy())\n",
        "    return w_grid;\n",
        "\n",
        "\n",
        "def train(lr):\n",
        "    model.train()\n",
        "    train_accuracy = []\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_history.append(loss.item())\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
        "\n",
        "    # Calculating training accuracy\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        train_accuracy.append(100 * correct / total)\n",
        "\n",
        "        print('Training accuracy is: {0:.2f} %'.format(100 * correct / total))\n",
        "\n",
        "    # Code to update the lr\n",
        "    lr *= learning_rate_decay\n",
        "    update_lr(optimizer, lr)\n",
        "\n",
        "\n",
        "def validate(max_val_acc):\n",
        "    model.eval()\n",
        "\n",
        "    # Checking validation accuracy\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        val_accuracy.append(100 * correct / total)\n",
        "\n",
        "        print('Validataion accuracy is: {} %'.format(100 * correct / total))\n",
        "\n",
        "        # Saving best model\n",
        "        if (correct / total > max_val_acc):\n",
        "            print(\"Saving the model...\")\n",
        "            torch.save(model.state_dict(), 'model_early.ckpt')\n",
        "            max_val_acc = correct / total\n",
        "    return max_val_acc\n",
        "\n",
        "\n",
        "def test():\n",
        "    # TESTING\n",
        "    model.eval()\n",
        "\n",
        "    # Load the best model\n",
        "    best_model = torch.load(\"model_early.ckpt\")\n",
        "    model.load_state_dict(best_model)\n",
        "\n",
        "    # Calculating test accuracy\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            if total == 1000:\n",
        "                break\n",
        "\n",
        "        print('Test Accuracy of the network on the {} test images: {} %'.format(total, 100 * correct / total))\n",
        "    return 100*correct/total\n",
        "\n",
        "\n",
        "model = ConvNet(input_size, hidden_size, num_classes, norm_layer=norm_layer).to(device)\n",
        "model.apply(weights_init)\n",
        "\n",
        "# Initialising mask with all ones\n",
        "for name, param in model.named_parameters():\n",
        "    mask_layerwise[name] = (torch.ones(param.size()).byte().to(device))\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=reg)\n",
        "loss_history = []\n",
        "\n",
        "# Train the model\n",
        "lr = learning_rate\n",
        "max_val_acc = 0\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train(lr)\n",
        "    max_val_acc = validate(max_val_acc)\n",
        "\n",
        "# Load the best model\n",
        "best_model_prune = torch.load(\"model_early.ckpt\")\n",
        "model.load_state_dict(best_model_prune)\n",
        "\n",
        "test()\n",
        "\n",
        "##############################################################################\n",
        "##############################################################################\n",
        "##############################################################################\n",
        "##############################################################################\n",
        "##############################################################################\n",
        "\n",
        "\n",
        "prune_accuracy = []\n",
        "prune_accuracy.append(max_val_acc)\n",
        "\n",
        "print(\"*********Pruning***********\")\n",
        "\n",
        "s = {}\n",
        "\n",
        "\n",
        "def prune(prune_percent, model, mask_layerwise):\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'weight' in name and '8' not in name:\n",
        "            sort_array = torch.sort(torch.abs(torch.masked_select(param, mask_layerwise[name])))[0]\n",
        "            thres_index = int(prune_percent * len(sort_array) / 100)\n",
        "            threshold = sort_array[thres_index]\n",
        "            new_mask = torch.where(torch.abs(param).cpu() <= threshold.cpu(),\n",
        "                                   torch.zeros(mask_layerwise[name].shape).byte().cpu(),\n",
        "                                   mask_layerwise[name].cpu()).byte().cuda()\n",
        "            mask_layerwise[name] = new_mask  # Updating mask\n",
        "        if '8.weight' in name:\n",
        "            sort_array = torch.sort(torch.abs(torch.masked_select(param, mask_layerwise[name])))[0]\n",
        "            thres_index = int(prune_percent * len(sort_array) / 200)\n",
        "            threshold = sort_array[thres_index]\n",
        "            new_mask = torch.where(torch.abs(param).cpu() <= threshold.cpu(),\n",
        "                                   torch.zeros(mask_layerwise[name].shape).byte().cpu(),\n",
        "                                   mask_layerwise[name].cpu()).byte().cuda()\n",
        "            mask_layerwise[name] = new_mask  # Updating mask\n",
        "\n",
        "\n",
        "for iter in range(prune_iter):\n",
        "    max_val_acc_prune = 0\n",
        "    val_accuracy_prune = []\n",
        "    train_accuracy_prune = []\n",
        "\n",
        "    # Pruning the network\n",
        "    prune(prune_percent, model, mask_layerwise)\n",
        "\n",
        "    # Training the pruned network\n",
        "    for epoch in range(num_epochs):\n",
        "        train(lr)\n",
        "        max_val_acc_prune = validate(max_val_acc_prune)\n",
        "\n",
        "    # Load the best model\n",
        "    best_model_prune = torch.load(\"model_early.ckpt\")\n",
        "    model.load_state_dict(best_model_prune)\n",
        "\n",
        "    acc = test()\n",
        "    prune_accuracy.append(acc)\n",
        "    print(\"Iteration no: \", iter + 1, \"Percent = \", prune_percent)\n",
        "\n",
        "plt.plot(prune_accuracy, label=\"Validation\")\n",
        "plt.show()\n",
        "\n",
        "# Save the model checkpoint\n",
        "# torch.save(model.state_dict(), 'model.ckpt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}